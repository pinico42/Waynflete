\documentclass[Master.tex]{subfiles}

\lstdefinelanguage{Turlang}
{
  morekeywords={
    function,
    bool,
    int,
    and,
    or,
    not,
    xor
  },
  sensitive=true, % keywords are not case-sensitive
  morecomment=[l]{//}, % l is for line comment
  morecomment=[s]{/*}{*/}, % s is for start and end delimiter
  morestring=[b]" % defines that strings are enclosed in double quotes
}
\lstset{language=Turlang}

\begin{document}

At roughly the same time, the English mathematician Alan Turing was constructing a totally different method of achieving the same goal: rather than a basic and heavily theoretical system, it was far more physical and far closer to the mechanical computers that eventually implemented the idea.

\subsection{Examples of simple Turing Machines}\label{sec:TMacIntro}
The Turing Machine is composed of two parts. Firstly, an ordered set of \textit{cells} of infinite\footnote{Many definitions of Turing Machines have the tape extending infinitely in one direction only - in fact for full functionality a tape extending infinitely in both directions is unnecessary.} length known as \textit{tape}. On each of these cells is one of a finite set of \textit{symbols} - either alphanumeric characters or the symbol which represents an empty cell. At a given point on this tape is a \textit{tape head} (or cursor) which is able to write symbols to the current cell. Secondly, a finite set of instructions known as \textit{states} contain finite-length sequences of operations known as the \textit{transition function} which the cursor enacts, and the states that the machine moves to after performing those operations. An example \textit{description} of a set of states would be: \cite{turing1936computablenumbers}

\medskip\noindent\begin{tabu} to \textwidth{XXXX}
    \multicolumn{2}{c}{\textit{Configuration}} & \multicolumn{2}{c}{\textit{Behavior}} \\
    \textit{state} & \textit{symbol} & \textit{transition function} & \textit{final state} \\
    \hhline{====}
    \multirow{1}{*}{$\mathbb{A}$} & None & P\texttt{0}, R & $\mathbb{B}$ \\
    \hhline{----}
    \multirow{1}{*}{$\mathbb{B}$} & None & R     & $\mathbb{C}$ \\
    \hhline{----}
    \multirow{1}{*}{$\mathbb{C}$} & None & P\texttt{1}, R & $\mathbb{D}$ \\
    \hhline{----}
    \multirow{1}{*}{$\mathbb{D}$} & None & R     & $\mathbb{A}$ \\
\end{tabu}

\noindent $\Rightarrow \mathbb{A}$

\medskip

This description table format shall be used to describe Turing Machine configurations. First of all, the final line describes the starting state ($\mathbb{A}$). When the machine begins an iteration on any one of these states, it first checks if the symbol aspect of the configuration is equal to the symbol currently under the cursor on the tape. If this condition is met, the transition function is carried out - P\textit{n} for any symbol \textit{n} prints the symbol \textit{n} on the tape under the cursor; E erases any symbol under the cursor\footnote{More formally, prints the empty cell symbol}; L moves the cursor to the left; R moves the cursor to the right. When these operations are completed, the state is set to that described in the last column (in future I shall describe this using the $\rightarrow$ symbol, for example $\rightarrow \mathbb{B}$). The machine then moves to the next iteration.

In this case, it is not difficult to see that as the machine runs, it leaves a sequence of alternating 0s and 1s on every other cell on the tape. With the use of the \textit{symbol} condition, this table can be simplified: \cite{turing1936computablenumbers}

\medskip\noindent\begin{tabu} to \textwidth{XXXX}
    \multicolumn{2}{c}{\textit{Configuration}} & \multicolumn{2}{c}{\textit{Behavior}} \\
    \textit{state} & \textit{symbol} & \textit{transition function} & \textit{final state} \\
    \hhline{====}
    \multirow{3}{*}{$\mathbb{A}$} & None & P\texttt{0}       & $\mathbb{A}$ \\
                                  & \texttt{0}    & R, R, P\texttt{1} & $\mathbb{A}$ \\ 
                                  & \texttt{1}    & R, R, P\texttt{0} & $\mathbb{A}$ \\ 
\end{tabu}

\noindent $\Rightarrow \mathbb{A}$

\medskip

It is again not difficult to see that this produces the same output as the previous machine, but this time using only one state.

An example of a more complex Turing machine is shown below, which generates the sequence \texttt{010110111011110111110...} again on alternate cells, beginning at the fifth cell. \cite{turing1936computablenumbers}

\medskip\noindent\begin{tabu} to \textwidth{XXXX}
    \multicolumn{2}{c}{\textit{Configuration}} & \multicolumn{2}{c}{\textit{Behavior}} \\
    \textit{state} & \textit{symbol} & \textit{transition function} & \textit{final state} \\
    \hhline{====}
    \multirow{1}{*}{$\mathbb{Q}$} & Any        & P\texttt{e}, R P\texttt{e}, R,  P\texttt{0}, R, R, P\texttt{0}, L, L & $\mathbb{A}$ \\
    \hhline{----}
    \multirow{2}{*}{$\mathbb{A}$} & \texttt{0} & R, P\texttt{x}, L, L, L                   & $\mathbb{A}$ \\
                                  & \texttt{1} &                                  & $\mathbb{B}$ \\
    \hhline{----}
    \multirow{2}{*}{$\mathbb{B}$} & Any        & R, R                             & $\mathbb{B}$ \\
                                  & None       & P\texttt{1}, L                            & $\mathbb{C}$ \\
    \hhline{----}
    \multirow{3}{*}{$\mathbb{C}$} & \texttt{x} & E, R                             & $\mathbb{B}$ \\
                                  & \texttt{e} & R                                & $\mathbb{D}$ \\
                                  & None       & L, L                             & $\mathbb{C}$ \\
    \hhline{----}
    \multirow{2}{*}{$\mathbb{D}$} & Any        & R, R                             & $\mathbb{D}$ \\
                                  & None       & P\texttt{0}, L, L                         & $\mathbb{A}$ \\
\end{tabu}

\noindent $\Rightarrow \mathbb{Q}$


\medskip

The operation of such a machine is significantly more complex than the earlier one - a full explanation of its operation can be found in appendix \ref{appendix:turingexampleexp}. Key to the operation is the fact that the tape begins with the sequence \texttt{e e 0} at the start of the tape (this method shall be used in future), and that cells are seperated into value cells and marker cells. On value cells (odd-numbered cells) the symbols of the output sequence are printed. Only the symbols \texttt{0} and \texttt{1} will ever be printed on these cells. To the right of each value cell is a label cell (an even-numbered cell). These cells will either be left empty or will contain a 'marker' symbol, which labels the symbol on the value cell to the left. These symbols can be erased and overwritten, and are not part of the output sequence. Only one label cell is needed to contain multiple markers, or more descriptive markers for a single value cell, as this can be achieved with a sufficiently rich variety of marker symbols. This method is frequently used by Alan Turing in \cite{turing1936computablenumbers}.

It is clear from this example that the operation of the Turing Machine is very different from that of an ordinary computer. However, the core components are still mostly present - conditionals in the form of the symbol tests in the second column, variables in the form of labels, and continuity and looping when a state triggers itself - a form of recursion. The end result is the same - a solution is produced in the form of the computable sequence written on the value squares, and the machine can continue this sequence without halting indefinitely. Unfortunately, the operation of this machine is somewhat complex and obfuscated. To simplify this, we will introduce a type of function for the Turing machine.

\subsection{\textit{M}-functions}\label{sec:mfunctions}

\textit{M}-functions, described by Turing in \cite{turing1936computablenumbers}, are effectively an extension of states. They are denoted by a lowercase letter and a set of arguments contained in brackets - arguments in gothic script refer to states (or other \textit{m}-functions), and arguments in italics refer to symbols. When an \textit{m}-function is triggered, the italic and gothic symbols in the description are substituted by the supplied arguments (similar to application in $\lambda$-Calculus). An example of an \textit{m}-function would be the function $\mathbb{f}$ below: \cite{turing1936computablenumbers}

\medskip\noindent\begin{tabu} to \textwidth{XXXX}
    \multicolumn{2}{c}{\textit{Configuration}} & \multicolumn{2}{c}{\textit{Behavior}} \\
    \textit{state} & \textit{symbol} & \textit{transition function} & \textit{final state} \\
    \hhline{====}
    \multirow{2}{*}{$\mathbb{f}$(\textit{a}, \textfrak{C}, \textfrak{E})}   & \texttt{e}              & L & $\mathbb{f}_1$(\textit{a}, \textfrak{C}, \textfrak{E}) \\
                                                                          & Not \texttt{e}          & L & $\mathbb{f}$(\textit{a}, \textfrak{C}, \textfrak{E})   \\
    \hhline{----}
    \multirow{3}{*}{$\mathbb{f}_1$(\textit{a}, \textfrak{C}, \textfrak{E})} & \textit{a}     &   & \textfrak{C} \\
                                                                          & Not \textit{a} & R & $\mathbb{f}_1$(\textit{a}, \textfrak{C}, \textfrak{E}) \\
                                                                          & None           & R & $\mathbb{f}_2$(\textit{a}, \textfrak{C}, \textfrak{E}) \\
    \hhline{----}
    \multirow{3}{*}{$\mathbb{f}_2$(\textit{a}, \textfrak{C}, \textfrak{E})} & \textit{a}     &   & \textfrak{C} \\
                                                                          & Not \textit{a} & R & $\mathbb{f}_1$(\textit{a}, \textfrak{C}, \textfrak{E}) \\
                                                                          & None           & R & \textfrak{E} 
\end{tabu}

\medskip

The function $\mathbb{f}$ takes three arguments - the states \textfrak{C} and \textfrak{E} and the symbol \textit{a}. It is not difficult to see that if $\rightarrow \mathbb{f}$($\mathbb{A}$, $\mathbb{B}$, x) the cursor would trigger $\mathbb{A}$ at the first occurrence of \texttt{x}. If no symbols \texttt{x} were found, \textfrak{E} would be triggered on the marker of the first empty value square.

The use of \textit{m}-functions greatly simplifies the table descriptions, as certain operations are common to many machines. Of course, any table description that includes or refers to \textit{m}-functions can be written as an ordinary table as described in \cref{sec:TMacIntro}. This is possible because of the finite nature of both states and symbols; simply by listing in separate rows under the same state every permutation of the finite symbols and states that the function could possibly take substituted in.

\subsubsection{Common Operations}

In this section a set of common and useful \textit{m}-functions are defined that will be used regularly in future.

\medskip\noindent\begin{tabu} to \textwidth{XXXXX}
    \multicolumn{2}{c}{\textit{Configuration}} & \multicolumn{2}{c}{\textit{Behavior}} \\
    \textit{state} & \textit{symbol} & \textit{transition\qquad function} & \textit{final state} \\
    \hhline{====}
    $\mathbb{e}$(\textit{a}, \textfrak{C}, \textfrak{E}) & - & - & $\mathbb{f}$(\textit{a}, $\mathbb{e}_1$(\textfrak{C}), \textfrak{E}) & \multirow{2}{80pt}{Erases first occurrence of symbol \textit{a}} \\
    \hhline{----}
    $\mathbb{e}_1$(\textfrak{C}, \textfrak{E}) & - & E & \textfrak{C}\\
    \hhline{====}
    $\mathbb{l}$(\textfrak{C}, \textfrak{E}) & - & L & \textfrak{C} & Moves cursor left\\
    \hhline{----}
    $\mathbb{r}$(\textfrak{C}, \textfrak{E}) & - & R & \textfrak{C} & Moves cursor right\\
    \hhline{====}
    $\mathbb{fl}$(\textit{a}, \textfrak{C}, \textfrak{E}) & - & - & $\mathbb{f}$(\textit{a}, $\mathbb{l}$(\textfrak{C}), \textfrak{E}) & Moves to left of \textit{a} \\
    \hhline{----}
    $\mathbb{fr}$(\textit{a}, \textfrak{C}, \textfrak{E}) & - & - & $\mathbb{f}$(\textit{a}, $\mathbb{r}$(\textfrak{C}), \textfrak{E}) & Moves to right of \textit{a} \\
    \hhline{====}
    $\mathbb{p0}$(\textfrak{C}, \textfrak{E}) & - & P\texttt{0} & \textfrak{C} & Prints \texttt{0} \\
    \hhline{----}
    $\mathbb{p1}$(\textfrak{C}, \textfrak{E}) & - & P\texttt{1} & \textfrak{C} & Prints \texttt{1} \\
    \hhline{----}
    $\mathbb{p}$(\textit{s},\textfrak{C}, \textfrak{E}) & - & P\textit{s} & \textfrak{C} & Prints \textit{s} \\
    \hhline{====}
    $\mathbb{n}$(\textfrak{C}, \textfrak{E}) & - & - & $\mathbb{f}$(\texttt{e}, $\mathbb{n}_1$(\textfrak{C}), \textfrak{E}) & \multirow{3}{80pt}{Moves to first empty (final) \textit{p}-square} \\
    \hhline{----}
    \multirow{2}{*}{$\mathbb{n}_1$(\textfrak{C})} & Any  & R, R & $\mathbb{n}_1$(\textfrak{C}) \\
                                                  & None & - & \textfrak{C} \\
    \hhline{====}
\end{tabu}

\medskip

\subsection{Data Structures and Pointers}

At this point, the similarity between Turing machines and modern computers becomes very clear. The machine is able to store information, from integers to strings of characters to images, as binary sequences of value square \texttt{0}s and \texttt{1}s - these shall be stored on the tape as memory. The first data structure we shall define is the simple boolean - only 1 bit (1 value square) long. In order to identify these sequences on the tape as booleans, we shall label the first character of the boolean with an identifier (we shall call these pointers) unique to that boolean variable - for example the symbol \texttt{\textbf{B}myvar} (bear in mind this is one symbol, not six) would mark a boolean named \textit{myvar}. Let us define some \textit{m}-functions to define and assign values to variables of the boolean type:

\medskip\noindent\begin{tabu} to \textwidth{XXXX}
    \multicolumn{2}{c}{\textit{Configuration}} & \multicolumn{2}{c}{\textit{Behavior}} \\
    \textit{state} & \textit{symbol} & \textit{transition function} & \textit{final state} \\
    \hhline{====}
    $\mathbb{\mathbf{b}def}$(\textit{p}, \textfrak{C}, \textfrak{E})   & - & - & $\mathbb{n}$($\mathbb{\mathbf{b}def}_1$(\textit{p}, \textfrak{C}), \textfrak{E}) \\
    $\mathbb{\mathbf{b}def}_1$(\textit{p}, \textfrak{C})   & - & P\texttt{0}, R, P\textit{p}, L & \textfrak{C} \\
    \hhline{====}
    $\mathbb{\mathbf{b}copy}$(\textit{r}, \textit{w}, \textfrak{C}, \textfrak{E})   & - & - & $\mathbb{fl}$(\textit{r}, $\mathbb{\mathbf{b}copy}_1$(\textit{w}, \textfrak{C}, \textfrak{E}), \textfrak{E}) \\
    \hhline{----}
    \multirow{3}{*}{$\mathbb{\mathbf{b}copy}_1$(\textit{w},\textfrak{C},\textfrak{E})} & \texttt{0} & - & $\mathbb{fl}$(\textit{w}, $\mathbb{p0}$(\textfrak{C}, \textfrak{E}), \textfrak{E}) \\
                                                                                       & \texttt{1} & - & $\mathbb{fl}$(\textit{w}, $\mathbb{p1}$(\textfrak{C}, \textfrak{E}), \textfrak{E}) \\ 
                                                                                       & Other & - & \textfrak{E} \\
\end{tabu}

\medskip

The first takes one pointer \textit{p}, finds the first free bit (value square) on the tape, writes the dummy value of \texttt{0} to it and marks it with \textit{p}. This method of appending makes the assumption that no value squares are left empty across the used tape - in order to preserve this, we shall only append to value squares directly at the end of the used tape, and we shall never erase (only overwrite fully) value squares. The second very simply finds the bit at pointer \textit{r}, and branches to write either \texttt{0} or \texttt{1} at the bit at the pointer \textit{w}.

\subsubsection{Boolean Operations}

As we did in $\lambda$-Calculus, we shall define boolean operations. Every operation will take one or many pointers as arguments, and write the evaluated result to another given pointer. The simplest of these we can create is the negator:

\medskip\noindent\begin{tabu} to \textwidth{XXXX}
    $\mathbb{\mathbf{b}not}$(\textit{r}, \textit{w}, \textfrak{C}, \textfrak{E})   & - & - & $\mathbb{fl}$(\textit{r}, $\mathbb{\mathbf{b}not}_1$(\textit{w}, \textfrak{C}, \textfrak{E}), \textfrak{E}) \\
    \hhline{----}
    \multirow{3}{*}{$\mathbb{\mathbf{b}not}_1$(\textit{w}, \textfrak{C}, \textfrak{E})} & \texttt{0} & - & $\mathbb{fl}$(\textit{w}, $\mathbb{p1}$(\textfrak{C}, \textfrak{E}), \textfrak{E}) \\
                                                                                       & \texttt{1} & - & $\mathbb{fl}$(\textit{w}, $\mathbb{p0}$(\textfrak{C}, \textfrak{E}), \textfrak{E}) \\ 
                                                                                       & Other & - & \textfrak{E} \\
\end{tabu}

\medskip
This is almost identical to the copying function, but inverting the written symbols. The definition of the remaining logical functions based on truth tables now becomes simple:

\medskip\noindent\begin{tabu} to \textwidth{XXXX}
    $\mathbb{\mathbf{b}and}$(\textit{a}, \textit{b}, \textit{w}, \textfrak{C}, \textfrak{E})   & - & - & $\mathbb{fl}$(\textit{a}, $\mathbb{\mathbf{b}and}_1$(\textit{b}, \textit{w}, \textfrak{C}, \textfrak{E}), \textfrak{E}) \\
    \hhline{----}
    \multirow{3}{*}{$\mathbb{\mathbf{b}and}_1$(\textit{b}, \textit{w}, \textfrak{C}, \textfrak{E})} & \texttt{0} & - & $\mathbb{fl}$(\textit{w}, $\mathbb{p0}$(\textfrak{C}, \textfrak{E}), \textfrak{E}) \\
                                                                                       & \texttt{1} & - & $\mathbb{\mathbf{b}copy}$(\textit{b}, \textit{w}, \textfrak{C}, \textfrak{E}) \\ 
                                                                                       & Other & - & \textfrak{E} \\
    \hhline{====}
    $\mathbb{\mathbf{b}or}$(\textit{a}, \textit{b}, \textit{w}, \textfrak{C}, \textfrak{E})   & - & - & $\mathbb{fl}$(\textit{a}, $\mathbb{\mathbf{b}or}_1$(\textit{b}, \textit{w}, \textfrak{C}, \textfrak{E}), \textfrak{E}) \\
    \hhline{----}
    \multirow{3}{*}{$\mathbb{\mathbf{b}or}_1$(\textit{b}, \textit{w}, \textfrak{C}, \textfrak{E})} 
                                                                                       & \texttt{0} & - & $\mathbb{\mathbf{b}copy}$(\textit{b}, \textit{w}, \textfrak{C}, \textfrak{E}) \\
                                                                                       & \texttt{1} & - & $\mathbb{fl}$(\textit{w}, $\mathbb{p1}$(\textfrak{C}, \textfrak{E}), \textfrak{E}) \\ 
                                                                                       & Other & - & \textfrak{E} \\
    \hhline{====}
    $\mathbb{\mathbf{b}xor}$(\textit{a}, \textit{b}, \textit{w}, \textfrak{C}, \textfrak{E})   & - & - & $\mathbb{fl}$(\textit{a}, $\mathbb{\mathbf{b}xor}_1$(\textit{b}, \textit{w}, \textfrak{C}, \textfrak{E}), \textfrak{E}) \\
    \hhline{----}
    \multirow{3}{*}{$\mathbb{\mathbf{b}xor}_1$(\textit{b}, \textit{w}, \textfrak{C}, \textfrak{E})} 
                                                                                       & \texttt{0} & - & $\mathbb{\mathbf{b}copy}$(\textit{b}, \textit{w}, \textfrak{C}, \textfrak{E}) \\
                                                                                       & \texttt{1} & - &  $\mathbb{\mathbf{b}not}$(\textit{b}, \textit{w}, \textfrak{C}, \textfrak{E}) \\ 
                                                                                       & Other & - & \textfrak{E} \\
\end{tabu}

\medskip
In each of these, the first argument \textit{a} is observed, and an action which either writes a \texttt{1} or \texttt{0}, or copies or negates from \textit{b} depending on the truth tables, in a very similar manner to $\lambda$-Calculus. Gradually, the cryptic and simplified language of Turing machines is yielding results similar to that of a computer.

\subsection{Scripted Configurations}
As we have moved into more and more complex Turing machine functions, it can be noted that the middle two columns of the description are becoming gradually more empty - this is due to the fact that their operation can be entirely represented within \textit{m}-functions. We have started doing so with the functions $\mathbb{l}$, $\mathbb{r}$, $\mathbb{p0}$, and $\mathbb{p1}$ - furthermore, it is not difficult to create conditional functions to replicate the operation of the second column.

\medskip\noindent\begin{tabu} to \textwidth{XXXX}
    \multirow{2}{*}{$\mathbb{if}$(\textit{c}, \textfrak{I}, \textfrak{O})} 
                                                                                       & \textit{c} & - & \textfrak{I} \\
                                                                                       & Other & - & \textfrak{O} \\
\end{tabu}

\medskip  

The function $\mathbb{if}$ takes a symbol argument, which is compared to the symbol under the cursor - if they are the same, the machine $\rightarrow$ \textfrak{I}; if not the machine $\rightarrow$ \textfrak{O}.
Since we have now entirely defined the operation of the machine in terms of \textit{m}-functions, we no longer have any need for the central two table columns. In continuing to define \textit{m}-functions, we could simply choose to omit these columns, or even omit the table altogether and use a clearer notation - in this case, for a definition of the if function but based on pointers: 

\begin{lstlisting}
ifp(r, c, I, O, E) = fl(r,
    if(c, I, O),
    E
)
\end{lstlisting}
While this syntax is more concise, it is still somewhat obfuscated. Therefore, we will use our function method to define what is effectively a list of commands for the machine which will be executed in order. The main difference in this system is that, as the \textfrak{C} argument is always the function that must be run when that function is completed (except in the case of the conditional function), on interpretation of the language the entire operation of the machine after that point must be passed as the \textfrak{C} argument to that function in order for the functions to be called sequentially\footnote{For clarity, I have ignored error handling (i.e. omitted the E argument).}. The following function main() defines variables \textit{var1} and \textit{var2}, and sets \textit{var2} to be \textit{var1} negated, or \texttt{1}.

\begin{lstlisting}
function main() {
	bdef(var1)
	bdef(var2)
	bneg(var1, var2)
}
\end{lstlisting}
This is equivalent to:

\begin{lstlisting}

main(C, E) = bdef(var1,
    bdef(var2,
        bneg(var1, var2, C, E), E
    ), E
)


\end{lstlisting}
with arguments for continuity and simple error correction. This, in turn, can be simplified into a description table.

\subsection{Universality}

Turing machines are truly remarkable entities. While $\lambda$-Calculus was able to mimic the operation of a modern computer (behaving like a purely functional programming language such as Haskell), its axioms were completely abstract - the conceptual operations of abstraction and application, while being probably more useful than Turing machines in terms of yielding practical results, were unlike anything which could actually be created in the real world. However, Turing machines are entirely grounded in physical reality, and it is totally conceivable how one could create such a machine, while still being able to produce results very similar to that of an imperative programming language such as C - data storage, typed and referenceable variables, and boolean logic, all performed as a sequence of commands. From these building blocks, integers and more complex concepts can be produced. This is the truly remarkable thing about Turing machines - they illustrate clearly how mechanisms can in fact solve computable problems. 

However, up to this point, computational ability has been measured by the potential of a machine to perform a variety of tasks that appear to demonstrate computation. This is not a sufficiently rigorous definition - a machine which seems to behave like a computer is not necessarily able to evaluate any computable function. For practicality's sake, it seems natural for Turing Machines to be chosen to be the pinnacle of computability: any machine that can be programmed in such a way that it emulates a Turing machine shall be called a  `Turing-complete' computer, and any problem a Turing machine can solve is a computable function.

It is unseemly that the abstract notion of computability relies necessarily on the specific design of the Turing machine: the idea of computability is a robust, almost Platonic reality, that Turing machines, $\lambda$-Calculus and all other effectively calculable devices, physical or theoretical, participate within equally. In fact, the idea of Turing-completeness presented earlier achieves this aim. This is the concept of Universality.

The main idea behind Universality is the concept of the Universal Machine, a machine which is able to entirely emulate another given system. As shown in \cite{turing1936computablenumbers}, a Turing machine can be configured in such a way that it emulates a Turing machine; this machine reads a description table from the start of the tape, and then produces the output that the machine described in the pre-written table would produce. Furthermore, $\lambda$-Calculus is also Turing-complete - this is demonstrated entirely in appendix \ref{appendix:lambdauniversaldemo}. This is done by producing a function that takes the current configuration of a Turing machine (in terms of the tape, state and description table) as input, and transforms it into the next configuration in sequence that a Turing machine would produce. This function would then be run repeatedly on the configuration using the \textbf{Y} combinator, hence emulating the action of Turing machines. Hence the $\lambda$-Calculus can produce a Universal Machine for Turing machines.

Most remarkably, Turing machines are in fact able to also emulate $\lambda$-Caluculus. This shall not be demonstrated directly, but it seems intuitive that a Turing machine could carry out processes of abstraction and application since they are at heart simple algorithmic processes; a Turing macihne would evaluate $\lambda$-terms in a similar way to how the human mind would. This leads us onto the remarkable fact that since Turing machines and $\lambda$-Calculus can produce Universal Machines for each other, each has the potential to perform any task the other can perform, and hence they are equal in power. Furthermore, many other theoretical methods of computation such as Kurt G\"odel's General Recursive Functions also share this equivalence \cite{copeland2002ctt}.

It therefore seems that the informal notion of computability can be formally defined with the use of one of these equivalent computational systems - this is a truly remarkable result, which produces a very strong basis for computability. With this test for computability in place, the question of whether World War 2 produced computing machines becomes apparently trivial.

\end{document}
